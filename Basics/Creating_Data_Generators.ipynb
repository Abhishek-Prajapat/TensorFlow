{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "412f009f",
   "metadata": {},
   "source": [
    "# Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4380428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras import layers, Sequential, utils, optimizers, losses\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cbe61a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(n_samples=10000, n_features=100, n_informative=30, n_classes=2, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa55a3b7",
   "metadata": {},
   "source": [
    "## Creating from tensor-slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b9ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one thing that not many know is this\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "\n",
    "# and that's not it. Say you need to give multiple labels then\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, (y, y, y)))\n",
    "\n",
    "# here x and y are both np arrays which you could get from df[column_name].values\n",
    "# Also this is most useful in case of image data where x could be image paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6824f207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(100,), dtype=float64, numpy=\n",
      "array([ 1.44139631, -2.16397307, -1.0746983 ,  0.6167084 ,  0.81272494,\n",
      "       -0.37931506,  1.83957514,  1.51234583,  0.44589029,  1.50567997,\n",
      "       -1.25721123, -0.73325893,  2.53283655, -0.04788257,  2.45528537,\n",
      "        1.15825488,  0.09460954, -1.30726863,  1.35940056,  5.40807878,\n",
      "       -1.10293851,  0.50705595, -0.11272453, -0.04159435,  0.21263728,\n",
      "        0.87173812, -2.48517499, -0.52114325, -2.02859787,  0.37754337,\n",
      "       -3.47345709, -3.82066813, -0.03392974, -4.14599599, -0.06448292,\n",
      "       -2.23823363,  5.05534458,  0.36371597,  2.93646623, -1.83519852,\n",
      "       -0.7117152 , -0.61727136,  0.36552579, -3.3839417 , -0.48179345,\n",
      "        0.70721297, -7.13466225, -1.78977258, -0.28585538, -0.99119017,\n",
      "        0.15939806,  1.02433043, -4.5889883 , -1.28176521, -7.20402419,\n",
      "       -0.98025049,  5.74923023,  2.14284388,  0.28325959,  1.53590254,\n",
      "       -0.19572223, -0.96396027, -0.64818018, -0.07757217, -4.78795003,\n",
      "        0.1821019 , -1.31669183,  1.09223736, -0.40832873, -1.25579619,\n",
      "        0.39338071, -0.39068319, -0.51413903, -0.44371698,  1.55180677,\n",
      "       -2.92969141, -0.60578156, -0.92179761,  0.84150818,  1.95454186,\n",
      "        4.63634368,  0.37789337, 21.04317485,  4.22134116, -0.48018193,\n",
      "        0.1757353 , -0.83068998, -0.92940463,  0.28704945, -1.73956853,\n",
      "        0.57231043,  1.79755307,  5.55263783,  3.39559894,  0.87173475,\n",
      "       -0.04404212,  1.37354018,  1.94955201,  1.5698822 ,  0.71504723])>, (<tf.Tensor: shape=(), dtype=int32, numpy=0>, <tf.Tensor: shape=(), dtype=int32, numpy=0>, <tf.Tensor: shape=(), dtype=int32, numpy=0>))\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25af53be",
   "metadata": {},
   "source": [
    "### Operations you could perform on this dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9a8ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_func(x, y):\n",
    "    # lets just take first 10 values from x\n",
    "    x = x[:10]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b674b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(aug_func, num_parallel_calls=4) # here num parallel calls are used for better multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e227e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A better way to set num_parallel_call value\n",
    "auto = tf.data.experimental.AUTOTUNE\n",
    "num_parallel_calls = auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75820549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
      "array([ 1.44139631, -2.16397307, -1.0746983 ,  0.6167084 ,  0.81272494,\n",
      "       -0.37931506,  1.83957514,  1.51234583,  0.44589029,  1.50567997])>, (<tf.Tensor: shape=(), dtype=int32, numpy=0>, <tf.Tensor: shape=(), dtype=int32, numpy=0>, <tf.Tensor: shape=(), dtype=int32, numpy=0>))\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4394eb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(5, 5, 10), dtype=float64, numpy=\n",
      "array([[[ 1.44139631e+00, -2.16397307e+00, -1.07469830e+00,\n",
      "          6.16708399e-01,  8.12724937e-01, -3.79315062e-01,\n",
      "          1.83957514e+00,  1.51234583e+00,  4.45890289e-01,\n",
      "          1.50567997e+00],\n",
      "        [ 4.31892199e+00, -2.27792415e+00, -7.23961335e-01,\n",
      "          1.76166922e+00,  2.76571512e-01,  6.04824936e-01,\n",
      "          6.88614105e+00, -2.44003434e+00, -9.89677825e-01,\n",
      "          6.12758188e+00],\n",
      "        [-5.06952569e+00, -1.13780019e+00, -6.41313352e-01,\n",
      "         -1.18308280e-01, -6.76752518e+00,  7.82262177e-01,\n",
      "         -1.99826482e+00,  2.67734943e-01, -3.77383393e-02,\n",
      "         -3.04714096e+00],\n",
      "        [ 8.44038180e-02, -1.50634307e+00,  9.83509747e-02,\n",
      "         -6.68776141e-01,  7.02835301e+00, -4.53985121e-01,\n",
      "          1.73456955e+00,  1.01156258e+00, -1.54480066e+00,\n",
      "          6.57667997e+00],\n",
      "        [-6.87051804e+00, -2.14150573e-01, -1.16124397e+00,\n",
      "          3.59379301e-01,  5.31002703e+00, -1.30167702e-01,\n",
      "          5.05660689e+00,  2.47140783e+00, -1.09467439e+00,\n",
      "          4.38329838e+00]],\n",
      "\n",
      "       [[-6.94591413e+00,  6.08580587e-01,  3.95034270e-01,\n",
      "         -8.10771002e-01,  9.67923114e-02, -1.97779662e-01,\n",
      "          3.75933787e+00, -1.01691098e+00,  3.31963018e-01,\n",
      "          3.95002793e+00],\n",
      "        [ 1.96161252e+00,  4.64662080e-01,  5.31074443e-01,\n",
      "          2.22875656e-01,  1.53400401e+00, -2.79571084e-01,\n",
      "          8.67414705e-01,  7.20732308e-01,  4.96636466e-02,\n",
      "          3.28335643e-01],\n",
      "        [ 2.41026778e+00, -1.46031287e+00,  1.08230292e-02,\n",
      "         -1.37160939e+00,  7.81441412e+00, -1.46669900e+00,\n",
      "         -2.49352072e+00,  4.71493497e-01, -6.81503207e-01,\n",
      "          4.58844819e+00],\n",
      "        [-4.47231617e+00,  2.57696945e-01,  3.81203438e-02,\n",
      "          5.77135700e-01, -1.93641149e+00, -7.02841765e-01,\n",
      "          2.05520755e-03, -1.06832464e+00,  1.60154009e+00,\n",
      "         -8.82014164e-02],\n",
      "        [ 5.25021443e+00, -3.89756275e-01, -1.91330107e-02,\n",
      "         -4.75516963e-01,  3.82463198e+00, -7.17086798e-01,\n",
      "          8.11524655e-01,  5.55931868e-01, -6.12240248e-01,\n",
      "          1.47286242e+00]],\n",
      "\n",
      "       [[-2.43571668e+00,  1.85401155e-01, -3.75034580e-01,\n",
      "          5.64904361e-01,  3.04128602e-01,  5.22577073e-01,\n",
      "         -5.58387371e+00,  8.34341634e-02,  1.73438902e-01,\n",
      "         -4.20520283e+00],\n",
      "        [-7.38694229e-01, -1.51737180e+00, -4.99118578e-02,\n",
      "         -5.80053534e-01,  4.66291536e+00,  7.81000340e-01,\n",
      "          1.88819892e+00,  1.79130922e+00, -5.73613368e-01,\n",
      "          9.10515900e-01],\n",
      "        [ 7.51334582e-01, -8.27930757e-01,  9.48274609e-02,\n",
      "          7.69493825e-02,  6.82477124e+00, -1.25345148e+00,\n",
      "         -2.97271130e+00, -7.81728058e-01, -3.90696171e-01,\n",
      "         -4.00255646e+00],\n",
      "        [-8.39641225e-02,  6.90477561e-01, -2.65828788e-02,\n",
      "         -2.39209563e-02, -1.11100675e+00, -7.63420682e-01,\n",
      "          5.79362010e-01,  5.83515731e-01,  9.39940153e-01,\n",
      "         -2.05240751e+00],\n",
      "        [-9.87882363e-02, -3.18827765e-01,  9.41404273e-01,\n",
      "         -7.99180738e-01, -4.23494646e+00,  9.48874112e-01,\n",
      "          2.80190431e+00, -1.73803695e-01,  1.96383102e-01,\n",
      "         -1.02070877e+00]],\n",
      "\n",
      "       [[-6.62661027e+00, -2.82031967e-01, -1.12477349e-01,\n",
      "         -1.77270843e-01,  4.53579512e+00, -1.49162553e+00,\n",
      "         -1.95715737e+00,  7.23660694e-01,  4.66694123e-01,\n",
      "          3.30953303e+00],\n",
      "        [-4.68233230e+00,  7.71137065e-01, -8.14934598e-01,\n",
      "          7.00516848e-01,  1.81892559e+00, -2.41226497e-01,\n",
      "         -6.63643159e+00,  8.62657376e-01,  6.64923675e-01,\n",
      "         -9.58379207e-01],\n",
      "        [ 8.84565359e-01, -1.61342790e-02,  2.06335903e-01,\n",
      "          1.09565516e-01,  5.64537869e-01,  6.30987079e-01,\n",
      "         -7.25169431e-01, -6.22948654e-01, -4.29099502e-01,\n",
      "         -4.81708627e+00],\n",
      "        [-3.62728374e+00, -6.87447397e-01,  9.15602830e-02,\n",
      "         -1.35963664e+00, -4.96239985e-01,  9.53300820e-01,\n",
      "          1.17760266e+00, -3.56492844e+00, -2.19466717e-01,\n",
      "          6.77746335e-01],\n",
      "        [-6.06514615e+00, -1.80834948e-01, -3.72588233e-02,\n",
      "         -1.10909321e+00, -4.37562921e+00,  7.46908218e-01,\n",
      "          1.24211790e+00, -7.15962003e-01, -1.53428757e+00,\n",
      "         -1.91837282e-01]],\n",
      "\n",
      "       [[ 3.18767127e+00,  1.86030685e-02,  3.48556386e-01,\n",
      "          7.35170773e-01, -3.22823052e+00,  5.62318238e-01,\n",
      "          5.17816372e-01,  2.43015554e-01, -1.32913040e+00,\n",
      "          4.56222341e+00],\n",
      "        [-6.12148230e-01,  1.09395715e+00,  1.18333787e+00,\n",
      "          1.72053654e-01,  7.61439076e+00,  1.55320916e+00,\n",
      "         -2.73962952e-01, -1.86340870e-01, -1.43256946e-01,\n",
      "          4.09822115e+00],\n",
      "        [ 5.22808303e+00, -7.55747358e-01,  2.11830429e-02,\n",
      "         -7.36605770e-01, -3.01692994e+00, -3.00282855e-01,\n",
      "         -3.40600519e+00, -2.26463675e+00,  2.69599346e-01,\n",
      "          1.88361972e+00],\n",
      "        [-2.41038007e+00,  5.12317194e-02,  1.10795114e-01,\n",
      "         -7.66561328e-01,  1.79534436e+00, -1.37663573e-01,\n",
      "          3.50000784e+00, -1.11390082e+00, -1.33822121e+00,\n",
      "          3.73090237e+00],\n",
      "        [-6.92808160e-02, -1.00089393e+00,  1.22079471e+00,\n",
      "         -3.25251568e-01, -7.48288757e+00, -1.18864724e+00,\n",
      "         -3.88314297e-01,  6.53570757e-01,  4.31905689e-01,\n",
      "          2.11019478e+00]]])>, (<tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n",
      "array([[0, 0, 1, 0, 1],\n",
      "       [0, 1, 0, 1, 1],\n",
      "       [0, 1, 0, 1, 1],\n",
      "       [1, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 1, 1]])>, <tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n",
      "array([[0, 0, 1, 0, 1],\n",
      "       [0, 1, 0, 1, 1],\n",
      "       [0, 1, 0, 1, 1],\n",
      "       [1, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 1, 1]])>, <tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n",
      "array([[0, 0, 1, 0, 1],\n",
      "       [0, 1, 0, 1, 1],\n",
      "       [0, 1, 0, 1, 1],\n",
      "       [1, 0, 0, 1, 0],\n",
      "       [1, 0, 0, 1, 1]])>))\n"
     ]
    }
   ],
   "source": [
    "# Taking a batch\n",
    "dataset = dataset.batch(5, num_parallel_calls=auto)\n",
    "\n",
    "# you can also prefetch the data part so that you getter even better performance\n",
    "dataset = dataset.prefetch(auto)\n",
    "\n",
    "for i in dataset:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e050f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now in the model you just need to pass x=dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778cc76e",
   "metadata": {},
   "source": [
    "## Creating the dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d11a5d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleDataset(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, x, y, batch_size=32, shuffle=True):\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index*self.batch_size : (index + 1)*self.batch_size]\n",
    "        y = self.y[index*self.batch_size : (index + 1)*self.batch_size]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "436a4bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72ef7161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 100), (3000, 100), (7000,), (3000,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8d2ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SampleDataset(x_train, y_train)\n",
    "test_dataset = SampleDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab45c46",
   "metadata": {},
   "source": [
    "## Creating and training a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e3b7b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "                [layers.Input(shape=(100, )),\n",
    "                layers.Dense(32, activation='relu'),\n",
    "                layers.Dense(16, activation='relu'),\n",
    "                layers.Dense(1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62990b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,777\n",
      "Trainable params: 3,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49543ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=1e-3)\n",
    "loss = losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aa027e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10000/10000 [==============================] - 8s 703us/step - loss: 3.7298 - acc: 0.7076\n",
      "Epoch 2/2\n",
      "10000/10000 [==============================] - 7s 715us/step - loss: 1.7336 - acc: 0.8601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29614a69f10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f82149a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 628us/step - loss: 1.5578 - acc: 0.8757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5577664375305176, 0.8756666779518127]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e70896",
   "metadata": {},
   "source": [
    "## Using predefined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50135517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_datagen():\n",
    "    for i in range(7000):\n",
    "        # img = Image.open(img_paths[idx])\n",
    "        # label = img_labels[idx]\n",
    "        img = x[i]\n",
    "        label = y[i]\n",
    "        yield img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f3d0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Dataset.from_generator(train_datagen,\n",
    "                               output_signature = (tf.TensorSpec(shape=(100,), dtype=tf.float64),\n",
    "                               tf.TensorSpec(shape=(), dtype=tf.int32))).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d19d33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.3239 - acc: 0.8914\n",
      "Epoch 2/5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.0354 - acc: 0.9130\n",
      "Epoch 3/5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8958 - acc: 0.9277\n",
      "Epoch 4/5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.8674 - acc: 0.9193\n",
      "Epoch 5/5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.7902 - acc: 0.9263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2961eb0ffa0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a268581",
   "metadata": {},
   "source": [
    "## One more Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a36892",
   "metadata": {},
   "source": [
    "If we have a dataframe containing the a column with the paths of the images we could use **ImageDataGenerator** to create a generetor which returns a batch of x and y with x being images and y being corresponding label.\n",
    "\n",
    "In case of multilabel classification you can pass a list of column names in the **y_col** parameter.\n",
    "Tutorial - <a href=\"https://vijayabhaskar96.medium.com/multi-label-image-classification-tutorial-with-keras-imagedatagenerator-cd541f8eaf24\">here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99542c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.preprocessing.image.ImageDataGenerator.flow_from_dataframe(self, dataframe, directory=None, x_col='filename', y_col='class', weight_col=None, target_size=(256, 256), color_mode='rgb', classes=None, class_mode='categorical', batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='png', subset=None, interpolation='nearest', validate_filenames=True, **kwargs)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageDataGenerator.flow_from_dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
